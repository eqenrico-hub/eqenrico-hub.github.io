---
title: "The measure of escape"
subtitle: "If distraction is the symptom of consciousness, its dosage measures its depth"
order: 8
excerpt: "If we distract ourselves because we know too much, and the more we know the more we distract ourselves, then the amount of distraction available in a society should tell us something about that society's level of consciousness."
---

In previous texts we established two things. First: distraction is our survival mechanism against the weight of consciousness — Zapffe was right, we know too much, and to avoid going mad we distract ourselves. Second: despite its price, consciousness might be worth what it costs — but the calculation is not obvious, it depends on how you weigh things, and no one can verify the assumptions.

But there is a question I have not yet asked. If distraction is proportional to consciousness — if we distract ourselves *because* we know, and the more we know the more we distract ourselves — then the amount of distraction available in a society should tell us something about that society's level of consciousness.

The idea is simple. If surviving existential anguish requires not thinking about it, and if that need grows with awareness, then distraction is like a fire extinguisher: the size of the extinguisher tells us something about the size of the fire.

This is not a scientific proposal in the strict sense. It is a thought experiment. But it has the advantage of offering something that philosophy of consciousness rarely offers: an observable indicator of something that seems unobservable.

Let us see if it holds.

## The monkey and the smartphone

The most immediate question is: does a monkey distract itself?

The answer is yes. But in a way that reveals everything.

Gordon Burghardt, ethologist at the University of Tennessee, in his *The Genesis of Animal Play* (2005), studied animal play across hundreds of species — from mammals to reptiles, from fish to octopuses. He identified five criteria for defining a behavior as "play": it must be voluntary, repeated, structurally different from functional behavior, and — crucially — it must be initiated under low-stress conditions, when the animal has surplus resources.

Play is animal distraction. But it is a poor distraction. A cat plays with a ball of yarn. A crow repeatedly slides down a snowy roof. An octopus manipulates objects for no apparent reason. Yet the range is limited: an animal cannot tell itself a story, build a mythology, invent a board game, write a song, watch a film, scroll a feed.

Francoise Wemelsfelder, ethologist and animal welfare researcher, studied what happens when animals *cannot* distract themselves. In monotonous, stimulus-poor environments, captive animals develop stereotypic behaviors: obsessive pacing, repetitive rocking, self-harm. Wemelsfelder, in *The Concept of Animal Boredom and Its Relationship to Stereotyped Behaviour* (1993), defines animal boredom as "that stage of behavioral fixation in which the animal's orientation towards a novel stimulus loses its inquisitive and manipulative character."

Translated: when an animal cannot distract itself, it breaks. But it breaks in a simple way — mechanical repetition, stereotypy. It does not develop existential depression, does not ask why it exists, does not drink to forget.

And here is the point. An animal needs distraction, but little. Its consciousness is limited, and the distraction it requires is proportionally limited. A primate has social play, grooming, environmental exploration. That is enough.

A human being needs Netflix, Instagram, video games, sports, alcohol, religion, philosophy, hobbies, gossip, music, podcasts, online shopping, doomscrolling, and six hours and forty minutes of screen time per day.

The difference is not merely technological. It is proportional.

## The brain that will not shut up

In 2001, Marcus Raichle, neuroscientist at Washington University, made a discovery that changed how we think about the resting brain. Using functional MRI, he identified a network of brain regions — the *Default Mode Network* (DMN) — that is *more active when we are doing nothing* than when we are engaged in a task.

The DMN activates when we daydream, when we think about the past or future, when we reflect on ourselves, when we try to understand what another person is thinking. It is the network of self-awareness. It is the neural substrate of existential anguish.

And here is the relevant finding: distraction turns it off.

When we focus on an external task — a film, a game, demanding work — the DMN is suppressed. We no longer ruminate. We no longer ask why we exist. We are "absorbed" in the activity. This is exactly what Zapffe called distraction, translated into neuroscience: a mechanism for silencing the part of the brain that reminds us who we are and that we will die.

The DMN exists in other mammals too. Mantini and colleagues (2011) found it in monkeys. Lu and colleagues (2012) found it in rats. But — and this is decisive — it is not the same.

Xu and colleagues, in a study published in *Cell Reports* in 2022, demonstrated that the coupling between medial prefrontal cortex (mPFC) and posterior cingulate cortex (PCC) — the central axis of the DMN, responsible for self-referential thought and existential reflection — is *significantly more developed in humans* than in any other primate. Human prefrontal gray matter is 1.9 times larger than that of macaques and 1.2 times larger than that of chimpanzees.

Translated: the human brain has an enormously more powerful existential-reflection network than any other animal. And when that network is active, we ruminate, we anguish, we question the meaning of everything. To turn it off, we need far more distraction than a monkey.

There is more. Excessive DMN activity — particularly the mPFC-PCC connection — is associated with depressive rumination. Greicius and colleagues (2007) and Sheline and colleagues (2009) showed that in patients with major depression, the DMN is hyperactive: the brain cannot "shut off," and the patient remains trapped in an infinite loop of self-reflection.

Depression, in this perspective, is the failure of distraction. The DMN that will not turn off. Consciousness that cannot be silenced.

## The four epochs of distraction

Merlin Donald, Canadian neuropsychologist, in his *Origins of the Modern Mind* (1991), proposed a model of human cognitive evolution in four stages. Each stage represents a leap in the capacity to think — and, implicitly, a leap in the capacity to distract oneself.

**Episodic culture** (shared with great apes). The animal lives in the present. It reacts to events as they occur. Memory is context-bound, not voluntarily retrievable. Distraction capacity: minimal — only play and immediate environmental stimuli.

**Mimetic culture** (Homo erectus, about 1.5 million years ago). A revolutionary improvement in motor control enables voluntary repetition of movements. Rituals, dance, complex tool manufacture emerge. First specifically human form of distraction: collective ceremony, rhythm, performance.

**Mythic culture** (Homo sapiens, about 100,000-50,000 years ago). With language come symbols, and with symbols comes narrative. Oral storytelling, mythology, invented stories. This is the decisive leap for distraction: for the first time, a living being can *exit reality* by entering an imaginary world. It can tell itself stories to avoid thinking about death. It can create gods who explain suffering. Distraction is no longer merely physical (play, ritual) — it is mental, symbolic, infinite in its potential.

**Theoretic culture** (beginning about 5,000 years ago, with writing). The invention of external memory — writing, then printing, then digital media — transforms the cognitive ecology. It is no longer about how many stories you can remember: it is about how many stories you can *access*. Each new external memory technology exponentially multiplies the material available for distraction.

Note the pattern: each stage of cognitive evolution brings more consciousness *and* more distraction. This is not a coincidence. If Donald is right and consciousness develops in stages, distraction develops in parallel — like the shadow of light.

## The philosophers knew

The idea that distraction is proportional to consciousness is not new. It is simply that no one has explicitly formulated it as an indicator.

Blaise Pascal, in the *Pensees* (1670), said it most directly: "All of humanity's problems stem from man's inability to sit quietly in a room alone." For Pascal, *divertissement* — diversion, distraction — is not a pastime: it is the necessary condition of human existence. The man who stops distracting himself finds himself face to face with his own misery, his own mortality, the void. No animal has this problem. Only us.

Arthur Schopenhauer, a century and a half later, went further. For Schopenhauer, boredom is "the force that mediates the invention of all forms of entertainment." We do not invent games, festivals, spectacles because we are creative. We invent them because we cannot bear the inner silence.

Soren Kierkegaard, in *Either/Or* (1843), describes the "rotation method" — the strategy by which the sophisticated aesthete avoids boredom not by seeking new stimuli (which are exhausted) but by changing the way he looks at the same stimuli. It is a form of meta-cognitive distraction: distracting oneself from the fact that distractions no longer work.

Martin Heidegger, in the *Fundamental Concepts of Metaphysics* lectures (1929-30), inverts everything. Heidegger does not want to cure boredom — he wants to *awaken* it. Profound boredom, he says, strips the illusion of meaning from things and reveals them for what they are: empty. But from that emptiness arises the possibility of authentic existence. Distraction, for Heidegger, is flight from being. And boredom is the door that distraction keeps shut.

All these philosophers, in different ways, are saying the same thing: distraction is proportional to the depth of consciousness. The more you see, the more you need to look away.

## Panem et circenses 2.0

If the philosophers' intuition is correct, then we should see distraction grow with civilization. And history does not disappoint.

Juvenal, Roman poet of the 1st-2nd century AD, in the *Satires* coined the expression *panem et circenses* — bread and circuses. He condemned it as degeneration: the Roman people had surrendered civic responsibility in exchange for free food and entertainment at the Colosseum. But what Juvenal could not see is that it was not degeneration. It was proportion. A more complex civilization, with a more developed collective consciousness, needed more distraction.

Under Julius Caesar, 320,000 people received free grain. The Colosseum, inaugurated in 80 AD, hosted gladiatorial spectacles before 50,000 spectators. It was the largest distraction infrastructure ever built up to that point.

But it was nothing.

Guy Debord, in 1967, with *The Society of the Spectacle*, diagnosed a qualitative leap. "All that once was directly lived has become mere representation." The spectacle is not a collection of images — it is a social relation among people, mediated by images. For Debord, distraction is no longer an activity for free time. It has become the organizing principle of society itself.

Neil Postman, in *Amusing Ourselves to Death* (1985), refined the diagnosis by comparing two dystopias: Orwell's, in which truth is suppressed by power, and Huxley's, in which truth is drowned in irrelevance and pleasure. Postman's conclusion: *Huxley was right*. No censors are needed when no one wants to read anymore. No repression is needed when everyone prefers to be distracted. The problem is not that we have spectacles — it is that the spectacle has become the way we communicate about everything: politics, religion, education, science.

And that was in 1985. Before the Internet. Before smartphones. Before social media.

## The dosage

Let us get to the numbers. If distraction is the thermometer of consciousness, the thermometer today reads high fever.

In 2024, the global average screen time is **6 hours and 40 minutes per day**. More than 40% of waking hours. Mobile devices account for 53% of this time, with an average of 4 hours and 37 minutes per day on the phone alone. Social media absorbs 2 hours and 31 minutes per day. Generation Z (ages 16-24) reaches **9 hours per day**.

Gloria Mark, professor of informatics at the University of California, Irvine, has measured attention capacity for twenty years. In 2004, the average attention duration on a single screen was 2 and a half minutes. By 2012, it had dropped to 75 seconds. Today, according to her most recent measurements published in *Attention Span* (2023), it is **47 seconds**.

Johann Hari, in *Stolen Focus* (2022), reports even more alarming data: American college students can focus on a single task for only **65 seconds**. Office workers for **3 minutes**. And after each interruption, it takes up to 25 minutes to return to previous concentration levels.

The global entertainment and media industry is worth **$2.9 trillion** (2024), with projected growth to $3.5 trillion by 2029. In 2024 alone, over 5,000 original series and 1,200 films were produced for streaming platforms, with global production budgets of approximately $60 billion. The video game industry generated $75 billion in in-app purchases and subscriptions alone.

For context: before the 20th century, the entertainment industry did not exist as an economic sector. Entertainment was local, artisanal, non-commercial. The trajectory from zero to $2.9 trillion in roughly one hundred years is one of the most rapid expansions of any human activity in history.

These numbers are impressive. But the question is: what exactly do they measure? The need to flee from consciousness — or the capacity of an industry to capture our attention?

## The serious objection

At this point, the critical voice says: you are confusing correlation with causation. And it is right, at least in part.

The strongest objection is this: the growth of distraction may not reflect a growth of consciousness. It may simply reflect a growth of *technology*. A human being in 50,000 BC may have been equally conscious, equally anguished by mortality, equally in need of distraction — but simply lacked the means to distract himself as we do. The tools were missing, not the need.

It is a valid objection. But it has a problem.

If the need had always been the same and only the tools were missing, then every civilization should have embraced each new distraction technology with identical enthusiasm. But that is not the case. The printing press took centuries to penetrate society. Radio took decades. Television took a decade. The smartphone took years. TikTok took months.

The acceleration is not merely technological. It is in *adoption* — in the speed at which society absorbs new forms of distraction. And that acceleration suggests that the need is growing, not just the supply.

A second objection: individual consciousness has not changed in 100,000 years. A Paleolithic Homo sapiens had the same brain we have. The same structures, the same DMN, the same prefrontal cortex. So how can consciousness have "grown"?

Here we must make a distinction. *Biological* consciousness — the structure of the brain — has not changed. But *informed* consciousness — what we *know* that we know — has exploded. A Homo sapiens of 50,000 years ago knew he would die. But he did not know that the universe is 13.8 billion years old, that the Earth is a speck in one galaxy among billions, that every atom in his body was forged in a dead star, that there is no plan, no design, no necessity in his existence. We know this. And that knowledge weighs.

The DMN of a Paleolithic human and the DMN of a modern human are structurally identical. But the *content* of what they ruminate on is radically different. A Paleolithic human could anguish over death, predators, winter famine. A modern human anguishes over cosmic insignificance, climate change, the collapse of meaning, a thousand possibilities he will never realize, the awareness that even his anguish is biologically irrelevant.

Same DMN. Much more fuel.

A third objection is subtler. The line between distraction, culture, and sublimation is blurred. Zapffe himself distinguished four mechanisms: isolation, anchoring, distraction, and sublimation. Is philosophy distraction? Is art distraction? Meditation — which is literally the opposite of distraction — is practiced by millions. Monks who seek *less* stimulation, not more. How does this reconcile?

It reconciles like this: distraction is not the only response to consciousness, but it is the *statistical* response. Meditation is the exception, not the rule. For every Zen monk there are ten million people scrolling Instagram. The fact that some individuals choose to face consciousness head-on does not invalidate the fact that the vast majority of the species prefers not to. And the statistics show that this preference is growing.

## The thermometer and the factory

But there is an objection more radical than the three above, and it must be faced.

Until the digital age, distraction was scarce. You had to seek it: go to the Colosseum, find a book, reach a theater. Supply was limited by physical reality. Under those conditions, distraction consumption roughly reflected demand — and demand, plausibly, reflected need.

Digital technology broke this proportionality. Infinite scroll, autoplay, notifications, recommendation algorithms — these do not respond to an existential need. They are attention engineering, designed to maximize screen time. Deirdre Barrett, evolutionary psychologist, in *Supernormal Stimuli* (2010), explains the mechanism: just as junk food exploits the evolved taste for sugar far beyond natural levels, digital distraction exploits evolved attention mechanisms far beyond any real need. A teenager spending 9 hours on TikTok is not necessarily more conscious than a medieval peasant. They have access to a stimulus more powerful than anything evolution prepared them for.

So the numbers — the $2.9 trillion, the 6 hours and 40 minutes, the 47-second attention span — are not a reliable thermometer. They measure a mixture of genuine need and the power of the trap. The signal is there, but it is buried in noise.

## What holds

After dismantling my own thesis with the strongest objections I can find, what remains?

A distinction remains.

The *quantity* of distraction is not a reliable indicator. But the *sophistication* — the *kinds* of distraction a mind manages to create — does correlate with cognitive complexity. And this correlation holds.

An animal cannot tell itself a story. A pre-linguistic hominid cannot invent a myth. A pre-literate civilization cannot produce a novel. A society without digital technology cannot build a world in which you never die.

Each leap in distraction sophistication corresponds to a leap in what the mind is capable of representing — and in what it needs to escape from. From play to ritual, from ritual to narrative, from narrative to book, from book to screen, from screen to virtual world. Donald's stages hold. The neurobiology holds: the DMN is more developed where consciousness is deeper, and distraction suppresses it. The philosophers were right: Pascal, Schopenhauer, Kierkegaard, Heidegger — the depth of consciousness is linked to the *complexity* of the need for escape.

Not to the hours. To the complexity.

## The right question

I started with a simple hypothesis: distraction measures consciousness. I arrive at something more honest.

*Qualitative* distraction — the forms of escape we invent — reflects the complexity of the mind that flees. No species invents forms of escape more elaborate than its consciousness requires. A cat does not need Netflix. A crow does not need mythology. We do. And the fact that our escapes have become entire worlds — stories, religions, philosophies, virtual universes — says something about the depth of what we are fleeing from.

But *quantitative* distraction — how much time we spend fleeing — also reflects the power of the trap. And today we live in the historical moment when the two have become inseparable. We no longer know how much of our distraction is a response to consciousness and how much is a response to the algorithm.

This is not a defeat for the thesis. It is a complication. The thesis worked elegantly through the analog world — from primate play to the Roman Colosseum, from oral myths to the printing press. Then the digital introduced a variable that breaks the proportionality: a supply of distraction that no longer needs demand in order to grow.

And so the right question is not "how much do we distract ourselves?" — because that number is now unreadable. The right question is: *what did we have to invent in order to stop thinking?*

If you want to know how deep a species' consciousness runs, do not count the hours it spends fleeing. Look at what it had to build in order to do so.
